# -*- coding: utf-8 -*-
"""malware detection

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VEr5BZnBVqP53EfL1Ro0_YW97x_qTPDm
"""

import pandas as pd
data=pd.read_csv("data.csv")

data

data.info()

print(data["CLASS"].value_counts())

from sklearn.model_selection import train_test_split

X = data.drop(columns=['CLASS','NAME'])
y = data['CLASS']  # Target variable (0 = Benign, 1 = Malware)

# Split into 80% training and 20% testing
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

from sklearn.ensemble import RandomForestClassifier

model = RandomForestClassifier(n_estimators=100,class_weight="balanced", random_state=42)
model.fit(X_train, y_train)

from sklearn.metrics import (
    accuracy_score,
    precision_score,
    recall_score,
    f1_score,
    confusion_matrix,
    classification_report,
    roc_auc_score
)

# Make predictions
y_pred = model.predict(X_test)

# Calculate metrics
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred, average='weighted')
recall = recall_score(y_test, y_pred, average='weighted')
f1 = f1_score(y_test, y_pred, average='weighted')
conf_matrix = confusion_matrix(y_test, y_pred)
class_report = classification_report(y_test, y_pred)

# For binary classification, add ROC AUC
try:
    roc_auc = roc_auc_score(y_test, y_pred)
except ValueError:
    roc_auc = "Not applicable for multi-class without probability scores"

# Print metrics
print(f"Model Accuracy: {accuracy * 100:.2f}%")
print(f"Precision: {precision:.4f}")
print(f"Recall: {recall:.4f}")
print(f"F1 Score: {f1:.4f}")
print(f"\nConfusion Matrix:\n{conf_matrix}")
print(f"\nClassification Report:\n{class_report}")

if isinstance(roc_auc, float):
    print(f"ROC AUC Score: {roc_auc:.4f}")
else:
    print(f"ROC AUC: {roc_auc}")

import pandas as pd
import numpy as np
import joblib
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC
from xgboost import XGBClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import accuracy_score

df = pd.read_csv('data.csv')  # Update with actual dataset

# Assuming 'LABEL' is the target variable (1 = Malware, 0 = Benign)
X = df.drop(columns=['NAME', 'CLASS'], errors='ignore')  # Drop non-feature columns
y = df['CLASS']

# Split dataset into train (80%) and test (20%)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Scale features for better performance
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Define models
models = {
    "RandomForest": RandomForestClassifier(n_estimators=100,class_weight="balanced", random_state=42),
    "DecisionTree": DecisionTreeClassifier(random_state=42,class_weight="balanced"),
    "SVM": SVC(kernel='linear', random_state=42,class_weight="balanced"),
    "XGBoost": XGBClassifier(use_label_encoder=False, eval_metric='logloss',class_weight="balanced"),
    "LogisticRegression": LogisticRegression(class_weight="balanced"),
    "KNN": KNeighborsClassifier(n_neighbors=5),
    "NaiveBayes": GaussianNB(),
    "MLP": MLPClassifier(hidden_layer_sizes=(64, 32), activation='relu', max_iter=400, random_state=42)
}

best_model = None
best_accuracy = 0

# Train & evaluate each model
for name, model in models.items():
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    acc = accuracy_score(y_test, y_pred)

    print(f"{name} Accuracy: {acc:.4f}")

    # Save the best model
    if acc > best_accuracy:
        best_accuracy = acc
        best_model = model

# Save the best model for future use
print(f"Best model saved: {best_model.__class__.__name__} with accuracy {best_accuracy:.4f}")

from sklearn.model_selection import GridSearchCV
from sklearn.ensemble import RandomForestClassifier

param_grid = {
    'n_estimators': [100, 300],
    'max_depth': [None, 10, 30],
    'min_samples_split': [2, 10],
    'min_samples_leaf': [1, 4]
}

rf = RandomForestClassifier()
grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, n_jobs=-1, scoring='accuracy')
grid_search.fit(X_train, y_train)

best_rf = grid_search.best_estimator_
print(f"Best RandomForest Parameters: {grid_search.best_params_}")

import pandas as pd

# Load the new APK feature data
new_data = pd.read_csv("features.csv")

# Extract features (remove 'NAME' as it isn't used in the model)
X_new = new_data.drop(columns=['NAME'])

# Make predictions
predictions = model.predict(X_new)

# Map predictions (1 -> Malware, 0 -> Benign)
prediction_labels = ['Malware' if pred == 1 else 'Benign' for pred in predictions]

# Add predictions to the DataFrame
new_data['PREDICTION'] = prediction_labels

# Show the predictions
print(new_data[['NAME', 'PREDICTION']])

import joblib

# Save the trained model to a file
joblib.dump(model, 'apk_model.pkl')